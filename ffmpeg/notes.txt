contents
-1- general
-2- stream selelction
-3- options
-4- other
	-4.1- webcam:
	-4.2- ffplay:
	-4.3- lavfi:
-5- filters
	-5.1- sync
-6- streaming
	-6.1- tcp
	-6.2- rtp
	-6.3- udp
	-6.4- listening rtsp
	-6.5- rtsp
		-6.5.1- mediamtx
		-6.5.2- keyframes
-7- concatenation
	-7.1- demuxer
	-7.2- protocol
	-7.3- filter

------------------------------
-1- general
------------------------------

ffmpeg [global options] [[input options] -i input] {[output options] -o output}

files:
N inputs and O outputs

files referred to by indices (0-based)
streams referred in format "I:S" for Sth stream in Ith input

all options are reset at each file

copying: use -codec copy: only perform mux/demux, no decode/encode

------------------------------
-2- stream selection
------------------------------
	-vn/ -an / -sn / -dn
	skips video, audio, subtitle, data streams

	option 1: automatic
		pick 1 stream from all inputs with priorties:
			highest resolution (video)
			most channels (audio)
			first matching subtitle encoder type (text vs image based)

	option 2: manual
		use -map option on an output file
		example:
			-map 1:a -c:a copy
				selects audio stream from file 1 and copies it
------------------------------
-3- options
------------------------------
	numerical options:
		all numerical options can accept a suffix of the units
		ie :
			K, M, G
			Ki, Mi, Gi
			add a B to indicate bytes instead of bits
	boolean options
		when present, set the value to True
		can be prefixed with "no" to make it false
		ex:
			-foo: foo is True
			-nofoo: foo is False
	stream specifiers:
		use a stream specifier to indicate
		which stream the option applies to
		if absent, matches all streams

queries:
	-pix_fmts: list pixel formats
	-formats : list valid formats
	-codecs  : list valid codecs
	-encoders: list encoders
	-decoders: list decoders
	-colors  : color names
	-sources : list autodetected sources

useful global options:
	-y       : overwrite output without asking
	-n       : no overwrite: exit instead
	-sinks   : autodetect sinks
	-v       : loglevel:
	            quiet: no logging
	            error: errors
	            warning: warnings and errors

argument formats:
	time:
		[-][HH:]MM:SS[.m...]
		[-]S+[.m...]
		- indicating negative duration
	resolution:
		[width]x[height]
	date:
		YYYYMMDD or YYYY-MM-DD
		for a date range, add a 'T' or 't' between the two dates
		Z at the end to indicate UTC otherwise local
		can also indicate now
AV options:
	-f fmt
	-i input
	-stream_loop number   : 0: no loop
	                        -1: infinite
	-use_wallclock_as_timestamps
		Use read time of the frames as the timestamp...??
	-c/-codec[:stream] codec
		copy for copy, otherwise codec
	-t duration
		for input: read this much
		for output: write this much
	-fs size
		filesize limit for output, stop writing once reached
	-ss pos
		for input: seek to position (closest point before position)
		for output: discard output until reach pos
	-sseof pos
		same as -ss except from eof (0 is at end, -HH:MM:SS before the end)
	-itsoffset offset
		add offset to input file timestamp (add positive offset for delay)
	-timestamp date
		recording timestamp
	-stdin
		allow stdin interaction
		boolean
V options:
	-frames number
		# of frames for output
	-r[stream] fps
		framerate (hertz, fraction, abbreviation)
	-video_size size
		[width]x[height]
			OR
		ntsc      720x480          uxga   1600x1200    hd1080  1920x1080
		pal       720x576          qxga   2048x1536    2k      2048x1080
		qntsc     352x240          sxga   1280x1024    2kflat  1998x1080
		qpal      352x288          qsxga  2560x2048    2kscope 2048x858
		sntsc     640x480          hsxga  5120x4096    4k      4096x2160
		spal      768x576          wvga   852x480      4kflat  3996x2160
		film      352x240          wxga   1366x768     4kscope 4096x1716
		ntsc-film 352x240          wsxga  1600x1024    nhd     640x360
		sqcif     128x96           wuxga  1920x1200    hqvga   240x160
		qcif      176x144          woxga  2560x1600    wqvga   400x240
		cif       352x288          wqsxga 3200x2048    fwqvga  432x240
		4cif      704x576          wquxga 3840x2400    hvga    480x320
		16cif     1408x1152        whsxga 6400x4096    qhd     960x540
		qqvga     160x120          whuxga 7680x4800    2kdci   2048x1080
		qvga      320x240          cga    320x200      4kdci   4096x2160
		vga       640x480          ega    640x350      uhd2160 3840x2160
		svga      800x600          hd480  852x480      uhd4320 7680x4320
		xga       1024x768         hd720  1280x720

	-vcodec
		video codec, alias for -codec:v
	-pixel_format[stream]
		pixel formats
	-aspect aspectratio
		a float (1.333)
		a ratio (4:3) (w:h)

	input:
		-framerate input framerate when framerate unavailable like image sequence
		-stream_loop loop the input, -1 = infinite, 0 = noloop

Video Segmentation:
	output format: segment
	useful:

	segment format:
		segment_atclocktime             0/1 start at the specified interval
		strftime                        output name is a strftime format string
		segment_time                    the duration of segment
		segment_clocktime_offset        offset from 00
		                                (every segment_time timeunit starting at segment_clocktime_offset)
		reset_timestamps                0/1 reset start time of each segment to 0
	encoder:
		-g, -keyint_min -> frames (seconds * fps)
		this should divide the segment interval for more accurate
		video segments.


------------------------------
-4-other
------------------------------
	------------------------------
	-4.1- webcam:
	------------------------------
	ffmpeg -f v4l2 -input_format h264 -video_size [width]x[height] -framerate fps -i /dev/video[x] [typical output stuffs]
	ffmpeg -f v4l2 -list_formats all -i /dev/video[x]

	ffmpeg -v error

	ffprobe -v error -show_entries stream=width,height -of csv=s=x:p=0 -i input

	ffmpeg -f dshow -list_devices true -i dummy
	ffmpeg -f dshow -list_options true -i video="name of webcam"

	------------------------------
	-4.2- ffplay:
	------------------------------
	-window_title title
	-seek_interval seconds      seconds to seek when left/right arrow

	------------------------------
	-4.3- lavfi:
	------------------------------
	lavfi format uses a filtergraph as the input to create video.
	ex. 5 seconds of pink frame:
		ffmpeg -f lavfi -t 5 -i color=pink

------------------------------
-5- filters
------------------------------
	-filter:v         filter for video, same as -vf
	-filter:a         filter for audio, same as -af
	-filter_complex   complex filter: multiple inputs/outputs

	-filter:[av] are tied to each video/audio individually.
	If N videos, then N filters are created, one per video source.

	filterchain: separated by ',' 1in, 1out chained together
	filtergraph: multiple filter chains interconnected, separated by ';'
	filter: a single filter
		[in1][in2]...filter_class_name@idnickname=arguments[out1][out2]...
		inputs/outputs
			syntaxes:
			N         the input/output index
			N:[av]:M  the Nth input audio/video stream M
			[name]    Give a name to the outputs
		arguments:
			explicit values: argname1=val1:argname2=val2:...
			implicit values: val1:val2:val3...
				(1 to 1 mapping with declared arguments of the filter (read docs for order))
			implicit values must come before explicit.

		list of argments can be quoted with ''

	Note that whitespace is ignored so you can split lines for readability.

	Characters are escaped with '\'
	NOTE: values are parsed:
	1. by the shell
	2. by the graph (to get filter+options)
	3. by the option

	ex: https://ffmpeg.org/ffmpeg-filters.html#Description
		target value: this is a 'string': may contain one, or more, special characters

		option:
			text=this is a \'string\'\: may contain one, or more, special characters

		graph:
			drawtext=text=this is a \\\'string\\\'\\: may contain one\, or more\, special characters

			NOTE: idk why the \: -> \\: instead of \\\:??

		shell:
			-vf "drawtext=text=this is a \\\\\\'string\\\\\\'\\\\: may contain one\\, or more\\, special characters"

		NOTE that some(?most?) filters allow putting options into a text file instead.


	------------------------------
	-5.0- expressions
	------------------------------
		------------------------------
		-5.0.1- numerical exprs
		------------------------------
		Many filter options can take expresions as values.
		Expressions include the standard add, subtract, multiply, divide (+-*/)
		as well as some function-like expressions.  NOTE bools are just int 0/1
		Expressions can be separated with ; for intermediate calculations (especially with ld/st functions)
		binary operators    + - * / ^
		unary operators     + -

		NOTE: * and + are like && and || for "truthy" bools (caveat, not if negative and positive...)

		functions
			abs(x)
			acos(x)
			asin(x)
			atan(x)
			atan2(y,x)
			between(x,min,max)    min <= x <= max
			bitand(x,y)
			bitor(x,y)
			ceil(xpr)
			clip(x,min,max)
			cos(x)
			cosh(x)
			eq(x,y)
			exp(x)
			floor(xpr)
			gauss(x)
			gcd(x,y)
			gt(x,y)       >
			gte(x,y)      >=
			hypot(x,y)    sqrt(x**2 + y**2)
			if(x,y)       x?y:0
			if(x,y,z)     x?y:z
			ifnot(x,y)    !x ? y : 0
			ifnot(x,y,z)  !x ? y : z
			isinf(x)
			isnan(x)
			ld(idx)       idxth internal variable
			lerp(x,y,z)   linear interpolation between x and y by z (x + (y-x)*z)
			log(x)
			lt(x,y)       <
			lte(x,y)      <=
			max(x,y)
			min(x,y)
			mod(x,y)
			not(xpr)
			pow(x,y)
			print(t)
			print(t,l)    print t at loglevel
			random(idx)   pseudorandom value 0-1, idx=internal variable for seed state
			randomi(idx, min, max) same as random, but ints, and from min to max
			root(xpr,max) Find a n input so that expr(ld(0)) is between 0 and max ??
			round(expr)
			sgn(x)        sign
			sin(x)
			sinh(x)
			sqrt(x)
			squish(x)     1/(1+e**(4x))
			st(idx, expr) store expr to idxth internal variable
			tan(x)
			tanh(x)
			taylor(expr, x)
			taylor(expr, x, idx)
			time(0)       wallclock in seconds
			trunc(expr)   round to 0
			while(cond, xpr)

		constants:
			PI    3.14
			E     2.718
			PHI   1.618 (golden ratio)

		prefixes    add i to use binary prefix instead (k=1000, ki=1024)
			y 10^-24
			z 10^-21
			a 10^-18
			f 10^-15
			p 10^-12
			n 10^-9
			u 10^-6
			m 10^-3
			c 10^-2
			d 10^-1
			h 10^2
			k 10^3
			K 10^3
			M 10^6
			G 10^9
			T 10^12
			P 10^15
			E 10^18
			Z 10^21
			Y 10^24


		------------------------------
		-5.0.2- colors
		------------------------------
		ffmpeg -colors for named colors

		Otherwise, colors are [0x|#]RRGGBB[AA][@0.A]
		where 0.A = alpha value as float 0-1


	------------------------------
	-5.1- sync
	------------------------------
	For filters with multiple inputs, the durations etc might be different
	These options are common and must be specified via name, positional is not allowed.

		eof_action      repeat  repeat last frame until all same length
		                endall  go til the shortest source
		                pass    "pass the main input through" ?? what does that mean? duplicate?

		shortest        0/1     same as eof_action=endall?
		repeatlast      0/1     same as eof_action=repeat?
		ts_sync_mode    default nearest lower or equal timestamp
		                nearest nearest timestamp


	------------------------------
	-5.2- useful filters
	------------------------------
		video sources:
			cellauto
			mptestsrc
			testsrc

			This is undocumented but it seems like there is also a color=c=value,... source filter
			that lavfi can use to get a solid-color frame...

		addroi
			xywh      left, top, width, height of the roi
			          expressions are allowed involving iw and ih (input width/height)
			          ex: iw/2 = half the input width
			qoffset   quantization offset, -1 = least quantization (best quality), 1 = most quant (worst quality)
			clear     true/false, clear any preexisting rois

		blend       blend frames from 2 sources
		tblend      blend consecutive frames from same source
			c{0..3}_mode      The blending mode for the specific channels of the sources.
			all_mode          ex. r, g, b, etc. all = all the channels use the same value.
			                  example values are: addition, interpolate, average, normal,
			                  and, or, overlay, reflect, etc

			c{0..3}opacity    opacity for specific pixel, only with pixel
			all_opacity       blend modes.

			c{0..3}_expr      blend expression. allowed variables:
			                  N: sequential number of filtered frame, from 0
			                  XY: pixel coordinates
			                  WH: width/height of image
			                  SW/SH: width/height scale, ratio of current plane dim to luma plane
			                         (ex, 1,1 for luma planes and .5,.5 for chroma planes for yuv420p)
                        T: time in seconds
                        TOP,A: top layer (first input) pixel value
                        BOTTOM,B :bottom layer (2nd input) pixel value
		boxblur
			luma_radius, lr       The size of the box, must be >= 0, and less than half the corresponding plane.
			chroma_radius, cr     usable variables: w,h (input shape), cw,ch (chroma shape),
			alpha_radius, ar      hsub/vsub chroma subsample values


			luma_power, lp        The number of applications
			chroma_power, cp
			alpha_power, ap
		colorchannelmixer
			rr rg rb ra       take the pixel as a vector and apply matrix transform onto it
			gr gg gb ga
			br bg bb ba
			ar ag ab aa

		convolution         apply convolution
			{0..3}m       matrix for channel {0..3}, only 3x3, 5x5, 7x7 square are allowed
			              or if flattened, then any odd number of weights.
			{0..3}rdiv    multiplier per plane after conv, 0 or unset implies 1/sum
			{0..3}bias    bias per plane after scale
			{0..3}mode    square | row | column

		convolve        use 2nd stream as "impulse" for convolution
			planes    which planes to process
			impulse   which frames, first | all

		crop
			w, out_w  output width/height eval once
			h, out_h

			x, y      left, top of cropping region, eval per frame

			expr vars:
				x, y                    x, y calculated for each frame
				in_w, in_h, iw, ih      input shape
				out_w, out_h, ow, oh    output shape
				a                       aspect ratio (iw/ih)
				sar                     input sample aspect ratio
				dar                     display aspect ratio (iw/ih)*sar
				hsv, vsub               hor/vert chromsa subsample values
				n                       number of input frame
				t                       timestamp, NAN if unknown

			keep_aspect   0/1 force display aspect ratio to be the same
			exact         do not round

		drawtext
			box           0/1     draw a box using background color
			boxborderw    int     width of box border
			boxcolor      color   defaults to white
			line_spacing  int     line spacing in pixels, 0
			text_align    flag    2 chars, vertical, horizontal:
			                      TMB for top middle, bottom
			                      LCR for left, center, right
			y_align       text        text top (default)
			              baseline    text bottom
			              font        baseline + ascent
			borderw       int     ? how dif to boxborderw?
			bordercolor   color
			expansion     none    ?as is?
			              normal  TODO
			fix_bounds    0/1     check/fix text coords to avoid clipping
			fontcolor     color   default black
			fontcolor_expr expr   expression for color overrides fontcolor if set
			font          name    Sans by default
			alpha         0-1     alpha blending
			fontsize      int     default 16
			shadowcolor   color   default black
			boxw          int     width around text
			boxh          int     height around text
			shadowx       int     shadow offset
			shadowy       int     shadow offset
			start_number  int     starting value for n/frame_num
			tabsize       int     size of a tab (default 4)
			timecode      str     timecode representation ??
			timecode_rate int     min 1 ??
			tc24hmax      0/1     wrap at 24 hours
			text          str     text to write, utf-8
			textfile      fname   file with text to draw
			reload        int     reload textfile every `reload` frames
			xy            int     where to write text

			variables:
				dar             display aspect ratio w/h*sar
				hsub/vsub       hor/vert subsample values
				line_h, lh      text line height
				main_h h H      input height
				main_w w W      input width
				max_glyph_a     from baseline to top of char >0
				max_glyph_d     from baseline to bottom of char (like bottom of g)  <0
				max_glyph_h     max_glyph_a - max_glyph_d
				max_glyph_w     max width of a char
				font_a          same as max_glyph_a?
				font_d          same as max_glyph_d?
				top_a           max ascender of first text line
				bottom_d        max descender of last text line
				n               number of frames
				rand(min,max)   random value
				sar             input aspect ratio
				t               timestamp in seconds
				th text_h       text height
				tw text_w       text width
				xy              the xy from options
				pict_type       1-character current frame type
				pkt_pos         current packet's position from start
				duration        current packet's duration
				pkt_size        size of packet

			text expansion
				none: verbatim, no expansion
				normal:
					use %{func:arg1:arg2...} to call functions
					functions:
						expr, e                an expression (text width/height not available because not calculated yet)
						expir_int_format, eif(xpr, fmt, width)
							fmt is x X d or u
						gmtime
							use a strftime c function format string
							extended to support %[1-6]N = N digits of fractional component
						localtime
							similar to gmtime
						n, frame_num
						pict_type
						pts

		extractplanes
			Extract color planes (input must be compatible)
			y, u, v, a, r, g, b
			syntax: extractplanes=y+u+v+...

		fps
			duplicate or drop frames to achieve fps
			fps           target fps
			              source_fps    input fps
			              ntsc          30000/1001
			              pal           25.0
			              film          24.0
			              ntsc_film     24000/1001
			start_time    first frame's pts (<0 to trim, >0 to pad)
			round         rounding mode
			              zero    truncate
			              inf     towards nearest inf (>0 -> inf, <0 -> -inf)
			              down    to -inf
			              up      to inf
			              near    nearest
			eof_action    reading last frame
			              round   use same rounding method as other frames.
			              pass    "pass through last frame if input duration has not been reached yet."
		framerate   achieve framerate by interpolating frames
			fps           output fps
			interp_start  start of range where output frame will be created, 0-255, default 15
			interp_end    specify end range of interpolation 0-255, default 240
			scene         0-100 probability for new scene
			flags         scene_change_detect, scd    enable scene change detection

		framestep   Take every Nth frame
			step  The N for frames to take

		fsync       sync input frame pts to a given file
			file, f   the file to sync to

		hflip       horizontal flip

		histeq      global color histogram equalization per-frame

		hstack      stack 2 vids horizontally
			inputs    number of inputs, default 2
			shortest  0/1 terminate on shortest input

		libplacebo  gpu-accelerated filtering

		loop        loop video frames
			loop      number of loops -1=infinite, default 0
			size      max frames, default 0
			start     first frame of loop, default 0
			time      When loop starts, only if start is -1

			NOTE: probably caches frames in memory, don't use with large
			      number of input frames, instead use -stream_loop input arg

		mergeplanes     merge color channels
			mapping       input to output plane mapping, default 0
			              0xAaBbCcDd, abcd from 0-3, which input SOURCE and which input PLANE
			format        output pixel format, default yuva444p
			map{0..3}s    set input STREAM mapping for Nth output plane
			map{0..3}p    set input PLANE mapping for Nth output plane

		minterpolate    motion interpolation
			fps           desired fps, a rational expr, default 60
			...

		mix         mix video sources by weight
			inputs    int, number of input sources
			weights   weights for each source, space-separated, repeats last weight if needed
			scale     scaling, defaults to 1/(sum of weights) ? or (sum of weights)?, it says "multiplied"
			          but is it actually divided?
			planes    int, 4-bit bitmask for which planes to filter
			duration  longest, shortest, first

		multiply    multiply first stream with 2nd stream (useful for masking?)
			scale     [0,9] scale of second video, 
			offset    [-1,1] offset of 2nd video stream, default 0.5
			planes    which planes to process

		negate          invert input video pixel values
			components    yuvargb
			negate_alpha  0/1, also negate alpha, default 0

		ocr         write recognized text to a metadata lavfi.ocr.text lavfi.ocr.confidence
			datapath  tesseract data path
			language  default "eng"
			whitelist character whitelist
			blacklist character blacklist

		ocv             filtering using opencv
			filter_name   dilate/erode/smooth
			filter_params ...

		overlay         place 2nd input on top of 1st input
			xy            overlaid video location expr
				variables:
					main_w, W     input width
					main_h, H     input height
					overlay_w, W  overlay width
					overlay_h, H  overlay height
					xy            allow referring to the other value
					hsbu, vsub    horz/vert chroma subsampling value
					n             the current frame number
					t             timestamp of frame, NAN if unknown
			eval          init    evaluate xy once at the start
			              frame   evaluate xy per frame
			format        output format
			              yuv420
			              yuv420p10
			              yuv422
			              yuv422p10
			              yuv444
			              yuv444p10
			              rgb
			              gbrp
			              auto
			alpha         straight
			              premultiplied
			              auto
			framesync options:
				eof_action
				shortest
				repeatlast

		pad         pad the frame
			width, w  padded width, 0 to use the input dim
			height, h padded height, 0 to use the input dim
			xy        input offset within the padded area, default 0
			          if < 0, center it
				variables:
				in_w in_h iw ih     input dims
				out_w out_h ow oh   output shape
				xy                  xy offsets or NAN if not specified yet
				a                   iw/ih
				sar                 input sample aspect ratio
				dar                 input display aspect ratio (iw/ih)*sar
				hsub vsub           horz/vert chroma subsample values

			color     padding color
			eval      when to eval x, y, w, h
			          init
			          frame
			aspect    pad to a ratio

		qrencode    generate qr code and put into video
			qrcode_width q            The width of qr code with and without padding.
			padded_qrcode_width Q     padded defaults to unpadded (default no padding)
			xy                        The qr code position in the video
			case_sensitive cs         0/1, whether encoding should be case sensitive
			level l                   QR encoding error correction level, higher = more robust but larger
			                          LMQH
			expansion                 [none|normal]
			text textfile             text or text template
			background_color bc       qr code color (default white)
			foreground_color fc       qr code color (default black)

		rotate          rotate a video
			angle a       angle in radians to rotate clockwise
			out_w ow      output width
			out_h oh      output height
				variables:
					n         frame count
					t         timestamp in seconds
					hsub vsub chroma subsampling
					in_w iw   input dimensions
					in_h ih
					out_w ow  output dimensions
					out_h oh
					rotw(a)   rotated width
					roth(a)   rotated height

			bilinear      0/1 enable bilinear interpolation
			fillcolor c   color of bg (no source pixels)

		scale                   resize the input
			width w               output video dimensions.
			height h              0 = use the input
			                      one -n: make the other dimension divisible by n
			                      both -n: same as both 0
			eval                  [init|frame]
			interl                1: force interlaced aware scaling
			                      0: do not
			                      -1: detect interlaced from input
			flags                 flags for libswscale
			param0                input parameters for libswscale
			param1
			intent                ICC rendering intent when transforming between color spaces
			                      perceptual
			                      relative_colorimetric
			                      absolute_colorimetric
			                      saturation
			size s                video size
			in_color_matrix       input/output YCbCr color space type
			out_color_matrix      [auto|bt709|fcc|bt601|bt470|smpte170m|smpte240m|bt2020]
			in_range              YCbCr sample range
			out_range             [auto/unkown|jpeg/full/pc|mpeg/limited/tv]
			force_original_aspect_ratio   [disable|decrease|increase]
			force_divisible_by    similar to negative value for wh, but also
			                      respect force_original_aspect_ratio
				variables:
					in_w in_h iw ih   input shape
					out_w out_h ow oh uotput shape
					a                 input aspect ratio
					sar               input sample aspect ratio
					dar               iw/ih*sar
					hsub vsub         input chroma subsample values
					ohsub ovsub       output chroma subsample values
					n                 framenum (eval=frame)
					t                 time (eval=frame)

		streamselect astreamselect      select video/auto stream
			inputs        number of inputs
			map           input indices to remap to

		transpose   transpose image with optional flip
			dir       cclock_flip 90 degrees counterclockwise and vertical flip
			          clock       90 degrees clockwise
			          cclock      90 degrees counterclockwise
			          clock_flip  90 degrees clockwise + flip
			passthrough   ignore transposing if [none|portrait|landscape]

		vflip       flip vertically

		vstack      stack sources vertically
			inputs    int, number of inputs, default 2
			shortest  0/1, terminate on shortest input?

		xstack      custom stacking layout
			inputs    int, number of inputs, default 2
			layout    output location per input source
			          '|' delimited strings of 'y_x'
			          can use wX or hX to use corresponding height/width instead.
			          can use + to sum values
			          ex: 3 videos: 0_0|w0_0|w0+w1_0 to put 3 videos side by side.
			grid      grid of inputs 'COLSxROWS', requires each input to match in width/height
			          within cols/rows
			shortest  0/1 terminate on shortest stream?
			fill      fill color for unused pixels

			NOTE: exactly one of grid or layout can be given.

		zscale          same as scale, but use z.lib
			width w       output dimensions
			height h      0: same as input
			              exactly one -n: maintain aspect ratio and ensure divisible by n
			              both -n: same as 0
			size s        widthxheight
			dither d      [none|ordered|random|error_diffusion] dithering
			filter f      [point|bilinear|bicubic|spline16|spline36|lanczos] resize filter type
			range r       [input|limited|full] color range
			primaries p   [input 709 unspecified 170m 240m 2020]
			transfer t    
			matrix m
			rangein rin
			primariesin pin
			transferin tin
			matrinxin min
			chromal c
			chromalin cin
			npl
			param_a
			param_b
			in_w in_h iw ih
			out_w out_h ow oh
			a
			sar
			dar
			hsub vsub
			ohsub ovsub

		segment asegment    split stream into multiple streams (opposite of concat)
			timestamps        timestamps of output segments separated by '|'
			frames samples    split by frames/samples
			NOTE: prefix values with a + to make it relative to previous segment

		setpts asetpts      change presentation timestamp (PTS)
			expr              Expression for the new presentation timestamp
			strip_fps         0/1 remove framerate info
				variables:
					FRAME_RATE FR         input framerate if constant framerate source
					PTS                   input PTS
					N                     current frame index
					NB_CONSUMED_SAMPLES   number of consumed samples excluding current
					NB_SAMPLES S          current sample index
					SAMPLE_RATE SR        audio sample rate
					STARTPTS              PTS of first frame
					STARTT                time in seconds of first frame
					INTERLACED            whether current frame is interlaced or not
					T                     time of current frame
					PREV_INPTS            previous PTS
					PREV_INT              previous time (seconds)
					PREV_OUTPTS           previous output PTS
					PREV_OUTT             previous output timestamp (seconds)
					RTCSTART              wall clock (RTC) at start of movie in microseconds
					TB                    timebase of input timestamps
					T_CHANGE              time of first frame after command was applied

------------------------------
-6- streaming
------------------------------
	source: https://trac.ffmpeg.org/wiki/StreamingGuide
	------------------------------
	-6.1- tcp
	------------------------------
	The receiver sets up a tcp listening socket waiting for incoming video.

	RECEIVER:
		ffmpeg -i tcp://RECEIVERhost:port?listen

	SENDER:
		ffmpeg -i INPUT -f mpegts tcp://RECEIVERhost:port

	NOTES:
		testing, can't find a format besides mpegts that works
		tried:
			h264: started streaming, then connection reset

	------------------------------
	-6.2- rtp
	------------------------------
	send via rtp

		SENDER:
			ffmpeg -i INPUT ... -f rtp rtp://host:port > sdpfile.sdp
		RECEIVER:
			ffmpeg -protocol_whitelist udp,file,rtp -i sdpfile.sdp ...

		NOTE:
			Any additional receiver fails with
				[udp @ 0x61d188c13400] bind failed: Address already in use
				live.sdp: Invalid data found when processing input

	ALTERNATIVE
		SENDER:
			ffmpeg -i INPUT ... -f rtp rtp://host:port > sdpfile.sdp

		INTERMEDIATE:
			httpserver serving the sdp file:
			python -m http.server

		RECEIVER:
			ffmpeg -i http://server:port/sdpfile.sdp ...

		NOTE:
			Any additional receivers fail with:
				[tcp @ 0x593550b9bd00] Connection to tcp://localhost:8000 failed: Connection refused
				http://localhost:8000/live.sdp: Connection refused

	NOTE: these do not work on vlc

	------------------------------
	-6.3- udp
	------------------------------
	The receiver sets up a udp listening socket, waiting for incoming video.

	RECEIVER:
		ffmpeg -i INPUT ... -f mpegts udp://RECEIVERhost:port

	SENDER:
		ffmpeg -i udp://RECEIVERhost:port


	------------------------------
	-6.4- listening rtsp
	------------------------------
	The receiver opens a server listening for an sdp.

	RECEIVER:
		ffmpeg -rtsp_flags listen -i rtsp://localhost:8888/live.sdp

		use rtsp://localhost:8888/live.sdp?tcp for tcp

	SENDER:
		ffmpeg -i INPUT -f rtsp rtsp://localhost:8888/live.sdp

		add -rtsp_transport tcp for tcp

	------------------------------
	-6.5- rtsp
	------------------------------
	FFmpeg does NOT have an rtsp server.  Instead, the output -f rtsp
	is a "publishing rtsp client", using rtsp ANNOUNCE.  A separate rtsp
	server is required to serve the the stream.
	-rtsp_flags listen on the receiver for `-6.4- listening rtsp` means
	it acts as its own rtsp server.  It's also why only 1 receiver
	is allowed for that case.

		------------------------------
		-6.5.1- mediamtx
		------------------------------
		is a simple no-dependency rtsp server that seems to be fairly good.

		https://github.com/bluenviron/mediamtx/releases

		The release tar.gz has a single executable.
		Start it up, ?maybe change config?

		Notes:
			ffmpeg streaming to port 8554 (tcp) works
			However, the 8000 (udp/rtp) and 8001 (udp/rtcp) does not seem
			to work... not sure why.  I tried the `-rtsp_transport udp`, changing
			the url to `rtp://`, etc, always failed with:
				[tcp @ 0x5d2154afed40] Connection to tcp://172.22.140.22:8001?timeout=0 failed: Connection refused
				Could not write header for output file #0 (incorrect codec parameters ?): Connection refused
				Error initializing output stream 0:0 --
			but tcp seems to work well at least...

		------------------------------
		-6.5.2- keyframes
		------------------------------
		Because using an rtsp server means clients can start streaming any
		time, keyframes matter.  Using ffmpeg to encode using h264, there is
		only a single key frame at the very beginning.  The result is that
		it has to loop to the very beginning before clients can start
		decoding frames/view the stream.

		h264
			-g frames
			-keyint_max frames
			-x264-params 'keyint=x:min-keyint=y'
		h265
			-x265-params 'keyint=x:min-keyint=y'
		vp9
			-g frames
			-keyint_max frames

------------------------------
-7- concatenation
------------------------------
ffmpeg concatenation has 2 methods
	------------------------------
	-7.1- demuxer
	------------------------------
	Use a txt file to concate files.
	Allows different formats (mp4, mkv, etc)
	requires same codec and timebase.
	syntax:
		# comments
		file 'path/to/file'

	ffmpeg -f concat -safe 0 -i lst.txt -c copy out.mp4

	-safe0 can be omitted if all paths are relative.

	------------------------------
	-7.2- protocol
	------------------------------
	like posix `cat`, so only certain streams work...

	------------------------------
	-7.3- filter
	------------------------------
	reencoding is required.
	number of streams must match
	may need scale or scale2ref filters to ensure same size/framerate

	example filter:
		ffmpeg -i f1 -i f2
			-filter_complex [0:v:0][0:a:0][1:v:0][1:a:0]concat=n=2:v=1:a=1[outv][outa]
			-map [outv] -ma [outa] out.mkv

		[N:av:0]
			specifies to use the v:0 or a:0 of the Nth -i
		concat=n=2
			indicates 2 segments
		v=1:a=1
			indicates 1 video 1 audio per segment

		The order would be determined by the input specification.
